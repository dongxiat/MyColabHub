import spaces
import os
import sys
import gradio as gr
import json
from huggingface_hub import login
from cached_path import cached_path
import tempfile
import soundfile as sf

# --- PHáº¦N 1: Äá»ŒC Cáº¤U HÃŒNH Tá»ª BIáº¾N MÃ”I TRÆ¯á»œNG ---
MODEL_TYPE = os.getenv('MODEL_TYPE', 'new')
CKPT_PATH = os.getenv('CKPT_HF_PATH')
VOCAB_PATH = os.getenv('VOCAB_HF_PATH')
WORD_LIMIT = int(os.getenv('WORD_LIMIT', 1000))
DISPLAY_NAME = os.getenv('DISPLAY_NAME', 'Unknown Model')
INIT_PARAMS_JSON = os.getenv('INIT_PARAMS_JSON', '{}')
INIT_PARAMS = json.loads(INIT_PARAMS_JSON)

# ÄÆ°á»ng dáº«n Ä‘áº¿n cÃ¡c thÆ° má»¥c thÆ° viá»‡n
PATH_TO_OLD_F5_REPO = os.path.abspath('f5_tts_old')
PATH_TO_NEW_F5_REPO = os.path.abspath('f5_tts_new')

if not CKPT_PATH or not VOCAB_PATH:
    raise ValueError("Lá»—i: CKPT_PATH hoáº·c VOCAB_PATH chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p.")

# --- PHáº¦N 2: Táº¢I MODEL & CACHING LOGIC ---
tts_instance = None
last_ref_audio_path = None

print(f"Nháº­n diá»‡n loáº¡i model: {MODEL_TYPE}")

if MODEL_TYPE == 'old':
    print("Äang táº£i model theo kiáº¿n trÃºc F5-TTS Base...")
    sys.path.insert(0, PATH_TO_OLD_F5_REPO)
    from f5_tts.model import DiT
    from f5_tts.infer.utils_infer import load_vocoder, load_model
    
    vocoder = load_vocoder()
    model = load_model(
        DiT,
        dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
        ckpt_path=str(cached_path(CKPT_PATH)),
        vocab_file=str(cached_path(VOCAB_PATH)),
    )
    tts_instance = {"model": model, "vocoder": vocoder}
    sys.path.pop(0)
    print("âœ… Táº£i model CÅ¨ thÃ nh cÃ´ng.")

elif MODEL_TYPE == 'new':
    print(f"Äang táº£i model vá»›i cÃ¡c tham sá»‘: {INIT_PARAMS}")
    sys.path.insert(0, PATH_TO_NEW_F5_REPO)
    from f5tts_wrapper import F5TTSWrapper

    # ThÃªm cÃ¡c tham sá»‘ báº¯t buá»™c vÃ o tá»« Ä‘iá»ƒn
    INIT_PARAMS['ckpt_path'] = str(cached_path(CKPT_PATH))
    INIT_PARAMS['vocab_file'] = str(cached_path(VOCAB_PATH))
    
    # DÃ¹ng unpacking Ä‘á»ƒ truyá»n táº¥t cáº£ tham sá»‘ tá»« INIT_PARAMS
    # Logic nÃ y váº«n Ä‘Ãºng sau khi Ä‘Ã£ sá»­a cáº¥u hÃ¬nh trong Colab
    tts_instance = F5TTSWrapper(**INIT_PARAMS)
    
    sys.path.pop(0)
    print("âœ… Táº£i model Má»šI thÃ nh cÃ´ng.")

def post_process(text):
    text = " " + text.replace('"', "") + " "
    text = text.replace(" . . ", " . ").replace(" .. ", " . ")
    text = text.replace(" , , ", " , ").replace(" ,, ", " , ")
    return " ".join(text.split())

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float, cfg_strength: float):
    global last_ref_audio_path
    if not ref_audio_orig:
        raise gr.Error("Vui lÃ²ng táº£i lÃªn má»™t tá»‡p Ã¢m thanh máº«u.")
    if not gen_text.strip():
        raise gr.Error("Vui lÃ²ng nháº­p ná»™i dung vÄƒn báº£n.")
    if len(gen_text.strip().split()) > WORD_LIMIT:
        raise gr.Error(f"VÄƒn báº£n quÃ¡ dÃ i. Giá»›i háº¡n lÃ  {WORD_LIMIT} tá»«.")
    
    try:
        if MODEL_TYPE == 'old':
            sys.path.insert(0, PATH_TO_OLD_F5_REPO)
            from vinorm import TTSnorm
            from f5_tts.infer.utils_infer import preprocess_ref_audio_text, infer_process, save_spectrogram

            final_text = post_process(TTSnorm(gen_text)).lower()
            ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
            
            final_wave, final_sr, spectrogram = infer_process(
                ref_audio, ref_text.lower(), final_text, tts_instance["model"], tts_instance["vocoder"], speed=speed
            )
            
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_file:
                save_spectrogram(spectrogram, tmp_file.name)
                spectrogram_path = tmp_file.name
            
            sys.path.pop(0)
            return (final_sr, final_wave), spectrogram_path

        elif MODEL_TYPE == 'new':
            sys.path.insert(0, PATH_TO_NEW_F5_REPO)
            from vinorm import TTSnorm
            
            if ref_audio_orig != last_ref_audio_path:
                print(f"PhÃ¡t hiá»‡n Ã¢m thanh máº«u má»›i. Äang xá»­ lÃ½: {ref_audio_orig}")
                tts_instance.preprocess_reference(
                    ref_audio_path=ref_audio_orig,
                    ref_text="",
                    clip_short=True
                )
                last_ref_audio_path = ref_audio_orig
                print(f"Xá»­ lÃ½ giá»ng máº«u thÃ nh cÃ´ng. Äá»™ dÃ i sá»­ dá»¥ng: {tts_instance.get_current_audio_length():.2f} giÃ¢y")
            else:
                print("Sá»­ dá»¥ng giá»ng máº«u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trÆ°á»›c Ä‘Ã³.")
            
            final_text = TTSnorm(gen_text)
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_wav:
                output_path = tmp_wav.name
            
            print(f"Äang táº¡o giá»ng nÃ³i vá»›i cfg_strength={cfg_strength}, speed={speed}...")
            
            tts_instance.generate(
                text=final_text,
                output_path=output_path,
                nfe_step=32,
                cfg_strength=cfg_strength,
                speed=speed,
                cross_fade_duration=0.15,
                sway_sampling_coef=-1,
            )
            print("Táº¡o giá»ng nÃ³i thÃ nh cÃ´ng.")
            
            # <<< Sá»¬A Lá»–I á» ÄÃ‚Y >>>
            # Äá»•i thá»© tá»± final_wave vÃ  final_sr Ä‘á»ƒ khá»›p vá»›i output cá»§a sf.read
            final_wave, final_sr = sf.read(output_path)
            
            sys.path.pop(0)

            # BÃ¢y giá» (final_sr, final_wave) sáº½ á»Ÿ Ä‘Ãºng Ä‘á»‹nh dáº¡ng (int, numpy_array)
            return (final_sr, final_wave), None

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Lá»—i khi táº¡o giá»ng nÃ³i: {e}")

# --- Giao diá»‡n Gradio khÃ´ng Ä‘á»•i ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤ F5-TTS: Vietnamese Text-to-Speech")
    gr.Markdown(f"### Model: **{DISPLAY_NAME}** | Kiáº¿n trÃºc: **{MODEL_TYPE.upper()}** | Giá»›i háº¡n: **{WORD_LIMIT} tá»«**")

    with gr.Row():
        ref_audio = gr.Audio(label="ğŸ”Š Ã‚m thanh máº«u", type="filepath")
        gen_text = gr.Textbox(label="ğŸ“ VÄƒn báº£n", placeholder="Nháº­p vÄƒn báº£n...", lines=3)
    
    with gr.Row():
        speed = gr.Slider(0.3, 2.0, value=1.0, step=0.1, label="âš¡ Tá»‘c Ä‘á»™")
        cfg_strength_slider = gr.Slider(0.5, 5.0, value=2.5, step=0.1, label="ğŸ—£ï¸ Äá»™ bÃ¡m sÃ¡t giá»ng máº«u", info="GiÃ¡ trá»‹ cao hÆ¡n sáº½ báº¯t chÆ°á»›c giá»ng máº«u máº¡nh hÆ¡n. Máº·c Ä‘á»‹nh ~2.0-3.0")
        
    btn = gr.Button("ğŸ”¥ Táº¡o giá»ng nÃ³i", variant="primary")
    
    with gr.Row():
        output_audio = gr.Audio(label="ğŸ§ Ã‚m thanh táº¡o ra", type="numpy")
        output_spectrogram = gr.Image(label="ğŸ“Š Spectrogram (Chá»‰ cÃ³ á»Ÿ model cÅ©)")

    btn.click(infer_tts, inputs=[ref_audio, gen_text, speed, cfg_strength_slider], outputs=[output_audio, output_spectrogram])

demo.queue().launch(share=True)